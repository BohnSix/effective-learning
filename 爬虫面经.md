1、自我介绍

2、介绍一下你的爬虫项目

3、apscheduler是怎么用的

4、spider怎么从redis中获取你存储的内容

5、twisted机制了解吗

6、介绍一下scrapy（组成、流程）

8、apk解包

9、自动化测试工具：appium了解吗

10、视频爬取有涉及吗？

11、自然语言处理这部分有涉及吗？


1. 为什么 requests 请求需要带上 header？

2. 谈一谈你对 Selenium 和 PhantomJS 了解

3. 写一个邮箱地址的正则表达式？

4. 你遇到的反爬虫策略有哪些？及应对策略有什么？

5. 分布式爬虫原理？

6. pythoon2.x 中urllib和urllib2的区别？

7. robots协议是什么？


http协议、tcp协议(几次握手)
top命令
Linu/Mac 下虚拟内存（Swap）
线程、进程、协程
Async 相关、事件驱动相关
阻塞、非阻塞
Python GIL
布隆过滤器原理：如何实现、一般要几次哈希函数

给我留下了一个作业：抓取天猫超市上某些商品的可以配送省份信息。
（当时做这个也花了很久，主要是需要解决PC端的登陆问题，后来通过h5接口）

问了下之前留给我的作业，各种详细的细节，每一步怎么做的，遇到了哪些问题，自己是怎么解决的
说了下淘宝登陆的两种方法，自己写的一些中间件
还问了些之前的项目细节，爬虫资源配置怎么做的
就我简历上的东西问了下底层的东西：线程与进程，协程用的Linux底层的是什么技术，事件驱动，MySQL的索引底层是什么，查询怎么做的等等。（这些问题都不知道）
验证码如何处理，TensorFlow训练成功率多少
redis快的原因是什么，底层原因，你平常用到了哪些数据结构
逆向是怎么学的，该怎么做，做过的项目，解决的签名
爬虫失败之后的重试是如何处理的，有没有针对具体的失败去做针对性的报警和重试

有没有阅读国内爬虫大厂、搜索引擎等开源的爬虫框架、思想之类的
scrapy会用到哪些中间件，各个中间件有什么功能
问了些websocket项目，是怎么找到协议的
验证码如何处理，TensorFlow训练成功率多少
wireshark报文如何查看
逆向是怎么学的，该怎么做，做过的项目，解决的签名
给我出了一道题目，关于JS混淆的。

用到了哪些linux命令，全写下来。我刚开始写了几个，他说太少了，让我再写几个，最后写了十几个
就我上面写到的命令问了下具体细节，比如crontab命令报错了可能有哪些原因
出了一道算法题，最终就是写排序算法

你说说点选验证码的正向校验流程和爬虫工程师的技术流程。
鼠标轨迹一般是怎么记录的？
怎么模拟鼠标轨迹，成功率高的算法有多高？
你用技术能通过哪几个验证码的验证？

你说说擅长哪些方面。
现在有一个场景，假设需要按预告时间爬取实时体育数据（例如篮球赛事，包括队伍比分、球员得分、阵容等），你如何确保爬虫程序能够及时、稳定且准确地将需求团队要求的数据传递过来？
说说网页端常见的反爬虫手段和解决的办法。
JavaScript 逆向你一般怎么做的，先如何，再如何？
如果遇到硬茬，你通常怎么做？
代码混淆的手段有哪些？怎么实现的？
APP 逆向你现在到什么程度？
讲讲 hook 原理和具体的操作过程。
有没有令人眼前一亮的反爬虫思路或者破解思路？
你现在技术方面有哪些瓶颈或者觉得可以提升的地方？

HTTP必须要有很深刻的理解，这是你纵横网络的立身之本；

BeautifulSoup、xpath这些都是基础操作了，一定要做到非常熟练；

Scrapy框架要会用，要能信手捏来写个分布式爬虫；

Webdriver、Selenium、PhantomJS也要会使用；
app 的数据采集、抓包工具的熟练使用

前端知识，尤其是常用的 js、ajax、html/xhtml、css 等相关技术为最佳。
